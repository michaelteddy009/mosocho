Data Science Ethics Checklist
Modeling
* D.1 Proxy discrimination: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?
* D.2 Fairness across groups: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?
* D.3 Metric selection: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?
* D.4 Explainability: Can we explain in understandable terms a decision the model made in cases where a justification is needed?
* D.5 Communicate bias: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?
Deployment
* E.1 Redress: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?
* E.2 Roll back: Is there a way to turn off or roll back the model in production if necessary?
* E.3 Concept drift: Do we test and monitor for concept drift to ensure the model remains fair over time?
* E.4 Unintended use: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?
Source: [Driven Data]